{"cells":[{"cell_type":"markdown","metadata":{"id":"cVB9pY-v8uv5"},"source":["# **RAG**\n","Retrieval Augmented Generation"]},{"cell_type":"markdown","metadata":{"id":"qTa9LlwZD_aa"},"source":["## **1.환경준비**"]},{"cell_type":"markdown","metadata":{"id":"gIN5d51gtker"},"source":["### (1) 라이브러리 Import"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"GVvCef6A8uv6"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import openai\n","\n","from langchain.chat_models import ChatOpenAI\n","from langchain.schema import HumanMessage, SystemMessage, Document\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.vectorstores import Chroma\n","from langchain.chains import RetrievalQA\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"]},{"cell_type":"markdown","metadata":{"id":"2fy_WT517dR2"},"source":["### (2) OpenAI API Key 확인\n","* 환경변수로 등록된 Key 확인하기"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"qIUl4r69hHcN"},"outputs":[{"name":"stdout","output_type":"stream","text":["sk-pr\n"]}],"source":["# 환경변수에서 키 불러오기\n","api_key = os.getenv('OPENAI_API_KEY')\n","print(api_key[:5])"]},{"cell_type":"markdown","metadata":{"id":"zIiu5Nld7dR2"},"source":["* 만약 환경변수 키 설정이 잘 안된다면 아래 코드셀의 주석을 해제하고, 자신의 api key를 입력하고 실행\n","    * 아래 코드는 키 지정을 **임시**로 수행함.\n","    * 파이썬 파일(.ipynb, .py)안에서 매번 수행해야 함."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UG-G64X87dR2"},"outputs":[],"source":["# os.environ['OPENAI_API_KEY'] = '여러분의 OpenAI API키'\n","# openai.api_key = os.getenv('OPENAI_API_KEY')"]},{"cell_type":"markdown","metadata":{"id":"mnk1VvHm2Ka0"},"source":["## **2.Vector DB**"]},{"cell_type":"markdown","metadata":{"id":"VB-24HkY7dR3"},"source":["### (1) Chroma DB 구성\n","\n","* DB 경로 지정\n","    * 없으면, 새로 폴더를 만들며 DB 생성\n","    * 있으면, 기존 DB 연결"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Xj5yt-Ufi1jU"},"outputs":[],"source":["embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n","\n","database = Chroma(persist_directory=\"./data\",  # 경로 지정(현 위치에서 db 폴더 생성)\n","                    embedding_function = embeddings  # 임베딩 벡터로 만들 모델 지정\n",")"]},{"cell_type":"markdown","metadata":{"id":"j4RgdhFr7dR3"},"source":["* DB 삭제는, 파이썬을 닫고 폴더를 삭제하면 됩니다."]},{"cell_type":"markdown","metadata":{"id":"7PkuEKUAobSn"},"source":["### (2) INSERT\n","\n","* 두가지 방법\n","    * (1) 단순 텍스트 입력 : 각 단위 텍스트를 리스트 형태로 입력 **.add_texts()**\n","    * (2) 텍스트와 메타데이터 입력 : 각 단위 텍스트와 메타정보를 함께 입력 **.add_documents()**"]},{"cell_type":"markdown","metadata":{"id":"837mZbiC7dR3"},"source":["#### 1) .add_texts()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Pzd20yaRjz73"},"outputs":[{"data":{"text/plain":["['eda1d41b-b7d4-416b-a98b-472e2871d3f2',\n"," '552289b0-0749-4459-82ab-bbac50302e99']"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["input_list = ['test 데이터 입력1', 'test 데이터 입력2']\n","\n","# 입력. 입력시 인덱스 저장(조회시 사용)\n","ind = database.add_texts(input_list)\n","ind"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"h5ijY2JY7dR4"},"outputs":[{"data":{"text/plain":["{'ids': ['552289b0-0749-4459-82ab-bbac50302e99',\n","  'eda1d41b-b7d4-416b-a98b-472e2871d3f2'],\n"," 'embeddings': None,\n"," 'metadatas': [None, None],\n"," 'documents': ['test 데이터 입력2', 'test 데이터 입력1'],\n"," 'uris': None,\n"," 'data': None}"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["database.get(ind)"]},{"cell_type":"markdown","metadata":{"id":"J0hMgHaH7dR4"},"source":["#### 2) .add_documents()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"q41_K-p97dR4"},"outputs":[],"source":["input_list2 = ['오늘 날씨는 매우 맑음. 낮 기온은 30도 입니다.', '어제 주가는 큰 폭으로 상승했습니다.']\n","metadata = [{'category':'test'}, {'category':'test'}]\n","\n","doc2 = [Document(page_content = input_list2[i], metadata = metadata[i]) for i in range(2)]\n","ind2 = database.add_documents(doc2)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"O6isuNz77dR4"},"outputs":[{"data":{"text/plain":["{'ids': ['c0786441-eaf6-453f-82b2-198709976f4a',\n","  'ec65eb62-443e-4a80-9d7f-d8c19eccc01b'],\n"," 'embeddings': None,\n"," 'metadatas': [{'category': 'test'}, {'category': 'test'}],\n"," 'documents': ['오늘 날씨는 매우 맑음. 낮 기온은 30도 입니다.', '어제 주가는 큰 폭으로 상승했습니다.'],\n"," 'uris': None,\n"," 'data': None}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["database.get(ind2)"]},{"cell_type":"markdown","metadata":{"id":"Z6iGAaet7dR5"},"source":["### (2) 조회"]},{"cell_type":"markdown","metadata":{"id":"Hp6xeWT47dR5"},"source":["#### 1) 전체 조회"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"2gCtE29Q7dR5"},"outputs":[{"data":{"text/plain":["{'ids': ['552289b0-0749-4459-82ab-bbac50302e99',\n","  'c0786441-eaf6-453f-82b2-198709976f4a',\n","  'ec65eb62-443e-4a80-9d7f-d8c19eccc01b',\n","  'eda1d41b-b7d4-416b-a98b-472e2871d3f2'],\n"," 'embeddings': None,\n"," 'metadatas': [None, {'category': 'test'}, {'category': 'test'}, None],\n"," 'documents': ['test 데이터 입력2',\n","  '오늘 날씨는 매우 맑음. 낮 기온은 30도 입니다.',\n","  '어제 주가는 큰 폭으로 상승했습니다.',\n","  'test 데이터 입력1'],\n"," 'uris': None,\n"," 'data': None}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["database.get()"]},{"cell_type":"markdown","metadata":{"id":"g98suRzu7dR5"},"source":["#### 2) 조건조회\n","* 일반적인 조건 조회를 지원하지 않음.\n","    * 그래서 전체를 다 불러와서\n","    * dataframe으로 변환 후 조건 조회"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"9ICrIQ417dR5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ids</th>\n","      <th>embeddings</th>\n","      <th>metadatas</th>\n","      <th>documents</th>\n","      <th>uris</th>\n","      <th>data</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>552289b0-0749-4459-82ab-bbac50302e99</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>test 데이터 입력2</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>c0786441-eaf6-453f-82b2-198709976f4a</td>\n","      <td>None</td>\n","      <td>{'category': 'test'}</td>\n","      <td>오늘 날씨는 매우 맑음. 낮 기온은 30도 입니다.</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ec65eb62-443e-4a80-9d7f-d8c19eccc01b</td>\n","      <td>None</td>\n","      <td>{'category': 'test'}</td>\n","      <td>어제 주가는 큰 폭으로 상승했습니다.</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>eda1d41b-b7d4-416b-a98b-472e2871d3f2</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>test 데이터 입력1</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                    ids embeddings             metadatas  \\\n","0  552289b0-0749-4459-82ab-bbac50302e99       None                  None   \n","1  c0786441-eaf6-453f-82b2-198709976f4a       None  {'category': 'test'}   \n","2  ec65eb62-443e-4a80-9d7f-d8c19eccc01b       None  {'category': 'test'}   \n","3  eda1d41b-b7d4-416b-a98b-472e2871d3f2       None                  None   \n","\n","                      documents  uris  data  \n","0                  test 데이터 입력2  None  None  \n","1  오늘 날씨는 매우 맑음. 낮 기온은 30도 입니다.  None  None  \n","2          어제 주가는 큰 폭으로 상승했습니다.  None  None  \n","3                  test 데이터 입력1  None  None  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data = database.get()\n","data = pd.DataFrame(data)\n","data"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"qKLurhUI7dR5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ids</th>\n","      <th>embeddings</th>\n","      <th>metadatas</th>\n","      <th>documents</th>\n","      <th>uris</th>\n","      <th>data</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>c0786441-eaf6-453f-82b2-198709976f4a</td>\n","      <td>None</td>\n","      <td>{'category': 'test'}</td>\n","      <td>오늘 날씨는 매우 맑음. 낮 기온은 30도 입니다.</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ec65eb62-443e-4a80-9d7f-d8c19eccc01b</td>\n","      <td>None</td>\n","      <td>{'category': 'test'}</td>\n","      <td>어제 주가는 큰 폭으로 상승했습니다.</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                    ids embeddings             metadatas  \\\n","1  c0786441-eaf6-453f-82b2-198709976f4a       None  {'category': 'test'}   \n","2  ec65eb62-443e-4a80-9d7f-d8c19eccc01b       None  {'category': 'test'}   \n","\n","                      documents  uris  data  \n","1  오늘 날씨는 매우 맑음. 낮 기온은 30도 입니다.  None  None  \n","2          어제 주가는 큰 폭으로 상승했습니다.  None  None  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["data.loc[data['metadatas'] == {'category': 'test'}]"]},{"cell_type":"markdown","metadata":{"id":"OCpjskYUvPaj"},"source":["#### 3) 유사 문서 조회"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"sxAdBcYtvUtF"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Document(page_content='오늘 날씨는 매우 맑음. 낮 기온은 30도 입니다.', metadata={'category': 'test'}), Document(page_content='어제 주가는 큰 폭으로 상승했습니다.', metadata={'category': 'test'}), Document(page_content='test 데이터 입력1')]\n","--------------------------------------------------\n","문서 내용: 오늘 날씨는 매우 맑음. 낮 기온은 30도 입니다.\n","문서 내용: 어제 주가는 큰 폭으로 상승했습니다.\n","문서 내용: test 데이터 입력1\n"]}],"source":["# 문서 조회1\n","query = \"오늘 낮 기온은?\"   # 질문할 문장\n","k = 3                      # 유사도 상위 k 개 문서 가져오기.\n","\n","result = database.similarity_search(query, k = k) #← 데이터베이스에서 유사도가 높은 문서를 가져옴\n","print(result)\n","print('-'*50)\n","for doc in result:\n","    print(f\"문서 내용: {doc.page_content}\") # 문서 내용 표시"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"70q4ZNZP7dR6"},"outputs":[{"name":"stdout","output_type":"stream","text":["[(Document(page_content='오늘 날씨는 매우 맑음. 낮 기온은 30도 입니다.', metadata={'category': 'test'}), 0.225577189858954), (Document(page_content='어제 주가는 큰 폭으로 상승했습니다.', metadata={'category': 'test'}), 0.3811175995977737), (Document(page_content='test 데이터 입력1'), 0.49498010226486283)]\n","--------------------------------------------------\n","유사도 점수 : 0.22558, 문서 내용: 오늘 날씨는 매우 맑음. 낮 기온은 30도 입니다.\n","유사도 점수 : 0.38112, 문서 내용: 어제 주가는 큰 폭으로 상승했습니다.\n","유사도 점수 : 0.49498, 문서 내용: test 데이터 입력1\n"]}],"source":["# 문서 조회2 : 유사도 점수도 함께 조회\n","query = \"오늘 낮 기온은?\"   # 질문할 문장\n","k = 3                      # 유사도 상위 k 개 문서 가져오기.\n","\n","result = database.similarity_search_with_score(query, k = k) #← 데이터베이스에서 유사도가 높은 문서를 가져옴\n","print(result)\n","print('-'*50)\n","for doc in result:\n","    print(f\"유사도 점수 : {round(doc[1], 5)}, 문서 내용: {doc[0].page_content}\") # 문서 내용 표시"]},{"cell_type":"markdown","metadata":{"id":"V7VGba8T7dR6"},"source":["### (3) 삭제\n","\n","* 문서의 id 값으로 삭제합니다."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"ZZNIPlLY0gIE"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ids</th>\n","      <th>embeddings</th>\n","      <th>metadatas</th>\n","      <th>documents</th>\n","      <th>uris</th>\n","      <th>data</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>552289b0-0749-4459-82ab-bbac50302e99</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>test 데이터 입력2</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>c0786441-eaf6-453f-82b2-198709976f4a</td>\n","      <td>None</td>\n","      <td>{'category': 'test'}</td>\n","      <td>오늘 날씨는 매우 맑음. 낮 기온은 30도 입니다.</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ec65eb62-443e-4a80-9d7f-d8c19eccc01b</td>\n","      <td>None</td>\n","      <td>{'category': 'test'}</td>\n","      <td>어제 주가는 큰 폭으로 상승했습니다.</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>eda1d41b-b7d4-416b-a98b-472e2871d3f2</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>test 데이터 입력1</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                    ids embeddings             metadatas  \\\n","0  552289b0-0749-4459-82ab-bbac50302e99       None                  None   \n","1  c0786441-eaf6-453f-82b2-198709976f4a       None  {'category': 'test'}   \n","2  ec65eb62-443e-4a80-9d7f-d8c19eccc01b       None  {'category': 'test'}   \n","3  eda1d41b-b7d4-416b-a98b-472e2871d3f2       None                  None   \n","\n","                      documents  uris  data  \n","0                  test 데이터 입력2  None  None  \n","1  오늘 날씨는 매우 맑음. 낮 기온은 30도 입니다.  None  None  \n","2          어제 주가는 큰 폭으로 상승했습니다.  None  None  \n","3                  test 데이터 입력1  None  None  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"eHavEJUn2SuH"},"outputs":[],"source":["ids = ['552289b0-0749-4459-82ab-bbac50302e99']\n","database.delete(ids = ids)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"l2eDQEy77dR6"},"outputs":[{"data":{"text/plain":["{'ids': ['c0786441-eaf6-453f-82b2-198709976f4a',\n","  'ec65eb62-443e-4a80-9d7f-d8c19eccc01b',\n","  'eda1d41b-b7d4-416b-a98b-472e2871d3f2'],\n"," 'embeddings': None,\n"," 'metadatas': [{'category': 'test'}, {'category': 'test'}, None],\n"," 'documents': ['오늘 날씨는 매우 맑음. 낮 기온은 30도 입니다.',\n","  '어제 주가는 큰 폭으로 상승했습니다.',\n","  'test 데이터 입력1'],\n"," 'uris': None,\n"," 'data': None}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["database.get()"]},{"cell_type":"markdown","metadata":{"id":"QB_QbTgj7dR6"},"source":["## **3.데이터 벡터화**"]},{"cell_type":"markdown","metadata":{"id":"pOyvrDfe7dR7"},"source":["### (1) DF to Vector DB"]},{"cell_type":"markdown","metadata":{"id":"5PuFfc847dR7"},"source":["* 샘플데이터 : 오픈소스 생성형 AI에서 주의해야 할 10가지 사항\n","    * 기사를 csv로 만든 것입니다.\n","\n","원문보기: https://www.ciokorea.com/news/337152#csidxc7d1d11066fad86a15937e4c3b29c6d\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"zskQXyDe2Sr4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>구분</th>\n","      <th>내용</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>낯선 라이선스 약관</td>\n","      <td>현재 오픈소스 AI 라이선스 유형은 다양한 만큼 매우 복잡하다. 오픈소스 AI 모델...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>낯선 라이선스 약관</td>\n","      <td>메타와 유사하게 애플은 ‘애플 샘플 코드 라이선스’하에 오픈ELM을 출시했다. 이 ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>전문성 부족</td>\n","      <td>오픈소스는 스스로 해야 하는 작업이 많을 수 있다. 기업은 코드를 다운로드할 수는 ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>전문성 부족</td>\n","      <td>업계 전체에 전문성이 부족하다는 점은 새로운 문제를 야기한다. 원래 오픈소스의 장점...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>탈옥</td>\n","      <td>LLM 공격 중 유명한 것에 탈옥(jailbreak)이라는 수법이 있다. 탈옥은 의...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>탈옥</td>\n","      <td>반면에 악의적인 공격자는 접근하기 쉬운 오픈소스 모델을 무료로 다운로드하여 자신의 ...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>학습 데이터가 가진 위험</td>\n","      <td>예술가, 작가, 기타 저작권 소유자들이 대형 AI 기업을 상대로 소송을 제기하고 있...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>학습 데이터가 가진 위험</td>\n","      <td>노탈의 수기스는 “대형 벤더는 학습 데이터를 구입하고 소송을 벌이는 데 쓸 돈이 있...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>새로운 보안 위협</td>\n","      <td>생성형 AI 프로젝트는 단순한 코드 그 이상이기 때문에 잠재적으로 보안 위협에 노출...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>새로운 보안 위협</td>\n","      <td>또 다른 공격 벡터는 모델의 시스템 프롬프트이다. 수기스에 따르면시스템 프롬프트는 ...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>누락된 가드레일</td>\n","      <td>오픈소스 그룹 일각에서는 AI 모델에 가드레일(허용 가능한 범위를 두는 일종의 가이...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>표준 부족</td>\n","      <td>오픈소스 기술을 소비하는 기업이 표준과 호환성을 중시하는 경우가 많다. 그래서 사용...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>표준 부족</td>\n","      <td>사실 많은 사람이 AI 표준에 대해 이야기할 때 윤리, 개인정보 보호, 설명 가능성...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               구분                                                 내용\n","0      낯선 라이선스 약관  현재 오픈소스 AI 라이선스 유형은 다양한 만큼 매우 복잡하다. 오픈소스 AI 모델...\n","1      낯선 라이선스 약관  메타와 유사하게 애플은 ‘애플 샘플 코드 라이선스’하에 오픈ELM을 출시했다. 이 ...\n","2          전문성 부족  오픈소스는 스스로 해야 하는 작업이 많을 수 있다. 기업은 코드를 다운로드할 수는 ...\n","3          전문성 부족  업계 전체에 전문성이 부족하다는 점은 새로운 문제를 야기한다. 원래 오픈소스의 장점...\n","4              탈옥  LLM 공격 중 유명한 것에 탈옥(jailbreak)이라는 수법이 있다. 탈옥은 의...\n","5              탈옥  반면에 악의적인 공격자는 접근하기 쉬운 오픈소스 모델을 무료로 다운로드하여 자신의 ...\n","6   학습 데이터가 가진 위험  예술가, 작가, 기타 저작권 소유자들이 대형 AI 기업을 상대로 소송을 제기하고 있...\n","7   학습 데이터가 가진 위험  노탈의 수기스는 “대형 벤더는 학습 데이터를 구입하고 소송을 벌이는 데 쓸 돈이 있...\n","8       새로운 보안 위협  생성형 AI 프로젝트는 단순한 코드 그 이상이기 때문에 잠재적으로 보안 위협에 노출...\n","9       새로운 보안 위협  또 다른 공격 벡터는 모델의 시스템 프롬프트이다. 수기스에 따르면시스템 프롬프트는 ...\n","10       누락된 가드레일  오픈소스 그룹 일각에서는 AI 모델에 가드레일(허용 가능한 범위를 두는 일종의 가이...\n","11          표준 부족  오픈소스 기술을 소비하는 기업이 표준과 호환성을 중시하는 경우가 많다. 그래서 사용...\n","12          표준 부족  사실 많은 사람이 AI 표준에 대해 이야기할 때 윤리, 개인정보 보호, 설명 가능성..."]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv('sample.csv', encoding='utf-8')\n","data"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"LXNJP03n7dR7"},"outputs":[],"source":["# Chroma 데이터베이스 인스턴스 생성\n","database = Chroma(persist_directory = \"./data3\", embedding_function = embeddings)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"EB_aVtjp7dR7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Document(page_content='현재 오픈소스 AI 라이선스 유형은 다양한 만큼 매우 복잡하다. 오픈소스 AI 모델을 이용하려면 상업적으로 사용해도 괜찮은지, 수정 및 배포가 가능한지, 사내 코드 베이스에 안전하게 통합할 수 있는지 등을 알아봐야 한다. 여기에 몇 가지 새로운 문제가 등장했다. 일단 이전에는 볼 수 없는 제약이 오픈소스 라이선스에 적용됐다.\\n메타의 라마(Llama) 라이선스를 예로 보자. 라마는 높은 인기를 자랑하는 오픈소스 LLM이다. 메타는 라마에 대해 ‘개방형 접근권을 제공하고 잠재적인 오용 문제를 해결하기 맞춤형 상용 라이선스 모델’을 적용한다고 밝혔다. 또한 이에 대해 ‘책임 및 보호 조치의 균형을 맞추기 위한 조치’라고 소개하고 있다.\\n이런 라이선스 하에 기업은 상업적으로 라마 모델을 사용할 수 있고 개발자는 기본 라마 모델 위에 추가 작업을 만들어 배포할 수 있다. 단 다른 LLM을 개선하기 위해 라마가 출력하는 결과물을 활용할 수는 없다. (라마 파생 모델은 제외된다.) 또한 기업 또는 그 계열사의 월간 사용자가 700명을 초과하는 경우, 메타에게 라이선스 사용 허락을 요청해야 한다. 메타는 이를 승인하거나 승인하지 않을 수 있다. 어떤 기업에서 라마 3를 사용해서 뭔가를 만들었다면, 눈에 잘 띄는 위치에 ‘Built with Llama 3(라마 3를 기반으로 구축했음)’라는 문구를 표기해야 한다.'), Document(page_content='메타와 유사하게 애플은 ‘애플 샘플 코드 라이선스’하에 오픈ELM을 출시했다. 이 라이선스 역시 특허권은 제외하고 저작권 권한만 명시하고 있다. 애플이나 메타 모두 일반적으로 통용되는 오픈소스 라이선스를 사용하지는 않지만, 실제로 코드는 공개되어 있다. 여기에 애플은 실제로 코드뿐만 아니라 모델 가중치, 훈련 데이터 세트, 훈련 로그, 사전 훈련 구성도 공개했다.\\n이제 오픈소스 라이선스의 또 다른 측면을 살펴보자. 기존의 오픈소스 소프트웨어에서 핵심은 ‘코드’였다. 그리고 그 코드를 통해 소프트웨어가 어떤 기능을 하는지, 잠재적인 문제나 취약점이 있는지 확인할 수 있었다.\\n하지만 생성형 AI는 단순한 코드가 아니다. 학습 데이터, 모델 가중치, 미세 조정도 마찬가지다. 이러한 모든 요소는 모델의 작동 방식을 이해하고 잠재적인 편향을 파악하는 데 매우 중요다. 예를 들어, 평평한 지구 음모론에 대한 자료를 학습한 모델은 과학 관련 질문에 제대로 답하지 못할 수 있다. 북한 해커가 미세 조정한 모델은 멀웨어를 정확하게 식별하지 못할 수 있다. 그렇다면 오픈소스 LLM은 이러한 모든 정보를 공개할까? 모델에 따라 다르다. 심지어 버전에 따라 다를 수도 있다. 그만큼 관련된 업계 표준이 없다.\\n카네기멜론 대학교의 AI 교수이자 전 PwC의 글로벌 AI 사업 총괄이었 아난드 라오는 “AI 모델에서 코드를 공개하는 경우도 있지만, 미세 조정 관련 정보가 없다면 비슷한 성능을 얻기 위해 많은 비용을 지출할 수 있다”라고 설명했다.'), Document(page_content='오픈소스는 스스로 해야 하는 작업이 많을 수 있다. 기업은 코드를 다운로드할 수는 있지만, 제대로 작동시키려면 사내 전문가나 외부 컨설턴트가 필요할 수 있다. 이는 생성형 AI 분야에서 큰 문제다. 이제 막 나온 기술과 관련해서 수년간의 경험을 가진 사람은 존재할 수 없다. 라오는 그런면에서 생성형 AI를 완전 처음 시작하거나 빠르게 도입하고 싶은 기업이라면 차라리 상용 플랫폼으로 시작하는 것이 더 안전하다고 조언했다.\\n라오는 “오픈소스 버전을 다운로드하려면 전문 지식이 필요하다”라며 “개념 증명을 완료하고 모델을 실제 제품에 배포 후 비용이 늘어나고 있다면, 오픈소스의 대안을 본격적으로 살펴봐야 할 것”이라고 설명했다.'), Document(page_content='업계 전체에 전문성이 부족하다는 점은 새로운 문제를 야기한다. 원래 오픈소스의 장점 중 하나는 수많은 사람이 코드를 살펴보고 프로그래밍 오류, 보안 취약점 및 기타 약점을 발견할 수 있다는 부분이다. 마치 외부의 ‘천개의 눈’으로 문제점을 공동으로 확인하는 셈이다. 기존의 오픈소스 소프트웨어야 수많은 전문가가 있어 천개의 눈을 가질 수 있었지만 AI 분야에서는 전문가가 부족하다. 천개의 눈을 아직 모으지 못했으니 보안 취약점에 제대로 대응하지 못할 수도 있다.'), Document(page_content='LLM 공격 중 유명한 것에 탈옥(jailbreak)이라는 수법이 있다. 탈옥은 의도적으로 사용자가 제시한 지침을 어기게 하고 멀웨어를 생성하도록 속이는 교묘한 프롬프트를 만드는 것이다. 일부 벤더는 탈옥 현상을 파악해서 알려주고 막는 서비스를 제공하고 있다. 오픈소스 모델에 보내는 메시지에 접근하며 의심스러운 활동의 징후를 모니터링하는 벤더도 있다.\\n악의적인 공격자가 비공개 환경에서 실행되는 엔터프라이즈 버전의 제품을 구매할 가능성은 낮다. 애초에 프롬프트 정보가 기업 내부에서만 입력되고 벤더에게 전송되지 않기 때문이다.'), Document(page_content='반면에 악의적인 공격자는 접근하기 쉬운 오픈소스 모델을 무료로 다운로드하여 자신의 환경에서 실행하며 해킹을 시도할 수 있다. 또한 모델이 사용하는 시스템 프롬프트와 안전 기능까지 다 볼 수 있기 때문에 탈옥을 위한 유리한 고지를 선점할 수 있다. 기업에선 오픈소스 AI 모델 전문 보안 담당자가 없는 경우가 많기 때문에 이런 공격에 취약할 수 있다. 라오는 “예를 들어 공격자는 학습 데이터를 분석하여 모델이 이미지를 잘못 식별하거나 사용자가 인식하지 못하게 문제 없어 보이는 프롬프트를 만드는 방법을 알아낼 수 있다”라고 설명했다.\\nAI 모델 출력물에 워터마크를 추가해도 공격을 막지 못할 수도 있다. 악의적인 공격자가 코드를 분석 및 리버스 엔지니어링을 통해 워터마크를 제거할 수 있기 때문이다. 또한 공격자는 모델이나 기타 지원 코드 및 도구를 분석하여 취약한 영역을 찾을 수도 있다.\\n컨설팅 업체인 노탈(Nortal)의 수석 데이터 과학자인 엘레나 수기스는 “공격자는 특정 요청을 계속 보내 인프라를 과부하시켜 모델이 작동하지 않도록 만들 수 있다”라며 “모델이 특정 시스템의 일부이고 모델 출력 결과가 시스템의 다른 부분에서 사용되는 경우 문제가 될 수 있다. 특히 모델의 출력 생성 방식을 공격할 수 있다면 전체 시스템이 중단될 수 있다. 기업에 매우 위험한 일이다”라고 말했다.'), Document(page_content='예술가, 작가, 기타 저작권 소유자들이 대형 AI 기업을 상대로 소송을 제기하고 있다. 하지만 오픈소스 모델이 지적재산권을 침해하고, 그 모델을 제품이나 서비스에 도입한 기업들만 큰돈을 벌고 있다면 어떻게 될까? 기업 사용자가 소송을 당할 수도 있을까?\\nEY의 구아레라는 “잠재적인 위험성은 있다. 법원에서 진행 중인 관련 소송이 어떤 결과를 맞이할지는 아직 아무도 모른다”라며 “데이터세트에 대한 보상이 있어야 하는 사회로 향하고 있을지도 모른다”라고 분석했다. 또한 구아레라는 “대형 기술 업체는 앞으로 늘어날 저작권 관련 위기를 극복하고 필요한 자금을 확보할 수 있는 더 나은 위치에 있다”라고 평가했다.'), Document(page_content='노탈의 수기스는 “대형 벤더는 학습 데이터를 구입하고 소송을 벌이는 데 쓸 돈이 있을 뿐만 아니라, 선별된 데이터 세트에 쓸 돈도 있다”라고 설명했다. 무료로 공개된 데이터 세트에는 합법적인 콘텐츠만 있는 것이 아니다. 일부는 저작권이 있는데 허가 없이 포함된 상태일 수 있다. 거기다 부정확하고 편향된 정보, 멀웨어 및 출력 품질을 저하시킬 수 있는 기타 자료도 들어가 있다.\\n수기스는 “많은 모델 개발자가 큐레이션된 데이터를 사용하자고 이야기하고 있다”라며 “하지만 그렇게 하려면 인터넷 전체를 학습시키는 것보다 비용이 더 많이 든다”라고 밝혔다. '), Document(page_content='생성형 AI 프로젝트는 단순한 코드 그 이상이기 때문에 잠재적으로 보안 위협에 노출될 수 있는 영역이 더 많다. LLM은 여러 방면에서 악의적인 공격을 받을 수 있다. 수기스에 따르면, 이들은 관리가 제대로 이루어지지 않는 프로젝트의 개발팀에 침투하여 소프트웨어에 바로 악성 코드를 추가할 수 있다. 거기서 끝나지 않고 훈련 데이터, 미세 조정 또는 가중치까지 오염시킬 수 있다.\\n수기스는 “해커는 예시 악성 코드로 모델을 재학습시켜 사용자 인프라에 침입할 수 있다”라며 “또는 가짜 뉴스와 잘못된 정보로 모델을 훈련시킬 수도 있다”라고 설명했다.'), Document(page_content='또 다른 공격 벡터는 모델의 시스템 프롬프트이다. 수기스에 따르면시스템 프롬프트는 일반 사용자에게 보통 공개되지 않는다. 시스템 프롬프트는 모델이 원치 않거나 비윤리적인 행동을 인식하는 안전망을 포함하고 있기에 중요하다. 수기스는 “해커가 시스템 프롬프트에 접근해서 모델을 공격하는 방법을 알아낼 수 있다”라고 설명했다.'), Document(page_content='오픈소스 그룹 일각에서는 AI 모델에 가드레일(허용 가능한 범위를 두는 일종의 가이드라인 또는 도구)을 두는 것 자체를 반대하기도 한다. 모델에 아무런 제한 없어야 더 나은 성능을 발휘할 것이라 믿는 곳도 있다. 기업은 현재 사용하는 오픈소스 모델이 가드레일에 대해 어떤 방향을 추구하는지조차 잘 모를 수도 있다.\\n수기스는 “현재 오픈소스 생성형 AI 모델의 안전성을 평가하는 독립적인 기관은 없다”라며 “유럽의 AI 법은 이러한 문서를 일부 요구할 것이지만, 대부분의 조항은 2026년에야 시행될 것”이라고 밝혔다. 또한 수기스는 “나라면 가능한 한 많은 문서를 확보하고, 모델을 테스트 및 평가하고, 회사 내부에 몇 가지 보호 장치를 마련할 것”이라고 밝혔다.'), Document(page_content='오픈소스 기술을 소비하는 기업이 표준과 호환성을 중시하는 경우가 많다. 그래서 사용자 주도의 오픈소스 프로젝트는 보통 기존에 나온 표준을 따를 때가 많다.\\n실제로 리눅스 재단이 약 500명의 기술 전문가를 대상으로 진행한 작년 설문조사에 따르면, 71%가 개방형 표준을 선호하는 반면, 폐쇄형 표준을 선호하는 응답자는 10%에 불과했다. 보통 상용 소프트웨어 업체는 고객이 자사 기술 생태계에 갇혀 있는 것을 선호한다. 오픈소스 기술은 다를 것이라고 기대할 수 있지만, 표준을 따르지 않는 생성형 AI 기술은 꽤 있다.'), Document(page_content='사실 많은 사람이 AI 표준에 대해 이야기할 때 윤리, 개인정보 보호, 설명 가능성 등을 이야기한다. 실제로 작년 12월에 발표된 ISO/IEC 42001 표준과 같은 작업이 해당 영역을 다루고 있다. 그리고 지난 4월 미국 국립표준기술연구소(NIST)는 AI 관련 공통 언어를 제시하는 등 AI 표준 계획 초안을 발표했다. 여기에선 주로 위험과 거버넌스 문제에 초점을 맞추고 있다. 그럼에도 기술 표준에 관해서는 아직 정해진 것이 많지 않다.\\n클라우드 네이티브 컴퓨팅 재단의 CIO인 테일러 돌잘은 “표준에 대한 논의는 매우 초기 단계에 머물러 있다”라며 ”단 데이터 분류, 학습 데이터, API, 프롬프트에 대한 표준 형식에 대해 의미 있는 논의가 이뤄지고 있다”라고 말했다. 그래도 아직 ‘논의’하는 수준일 뿐이다.')]\n"]}],"source":["# 데이터프레임의 텍스트 열(시리즈)을 리스트로 변환\n","text_list = data['내용'].tolist()\n","\n","# 리스트 내용을 각각 document로 변환\n","documents = [Document(page_content=text) for text in text_list]\n","\n","print(documents)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"CcZukOdX7dR7"},"outputs":[{"data":{"text/plain":["['434286ec-fa88-41dc-b4f7-f2fbdbfafc04',\n"," '17b883ce-2604-411a-a2f9-f5ec577328d9',\n"," '9aee1e86-1dbd-4f3e-9974-ad8a1363d3eb',\n"," '9074e286-6f02-4def-87c7-f18c97f8a46f',\n"," '256c0b63-a21b-4d5f-994f-96e2ee8f360a',\n"," '82279039-baed-41ca-a73f-0684e2b1aacb',\n"," '45a081fc-6d08-477e-a425-59d5e90c8956',\n"," 'b2b8d9a6-4707-49c1-b47d-418cf5f0b8a2',\n"," '023c1eb8-d8a6-4ca0-8508-ac390348544c',\n"," '456bf371-cf7c-471a-94f4-ac8d1e4b25ec',\n"," '8813f7ba-5cd3-492e-82c3-f817dd0e3d20',\n"," '5916f005-d6ea-40a6-8ab7-7681e235e3ba',\n"," 'c897dc28-1398-496b-9611-dbea44104b29']"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# Insert\n","database.add_documents(documents)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"jlKgj8Of7dR8"},"outputs":[{"data":{"text/plain":["{'ids': ['023c1eb8-d8a6-4ca0-8508-ac390348544c',\n","  '17b883ce-2604-411a-a2f9-f5ec577328d9',\n","  '256c0b63-a21b-4d5f-994f-96e2ee8f360a',\n","  '434286ec-fa88-41dc-b4f7-f2fbdbfafc04',\n","  '456bf371-cf7c-471a-94f4-ac8d1e4b25ec',\n","  '45a081fc-6d08-477e-a425-59d5e90c8956',\n","  '5916f005-d6ea-40a6-8ab7-7681e235e3ba',\n","  '82279039-baed-41ca-a73f-0684e2b1aacb',\n","  '8813f7ba-5cd3-492e-82c3-f817dd0e3d20',\n","  '9074e286-6f02-4def-87c7-f18c97f8a46f',\n","  '9aee1e86-1dbd-4f3e-9974-ad8a1363d3eb',\n","  'b2b8d9a6-4707-49c1-b47d-418cf5f0b8a2',\n","  'c897dc28-1398-496b-9611-dbea44104b29'],\n"," 'embeddings': None,\n"," 'metadatas': [None,\n","  None,\n","  None,\n","  None,\n","  None,\n","  None,\n","  None,\n","  None,\n","  None,\n","  None,\n","  None,\n","  None,\n","  None],\n"," 'documents': ['생성형 AI 프로젝트는 단순한 코드 그 이상이기 때문에 잠재적으로 보안 위협에 노출될 수 있는 영역이 더 많다. LLM은 여러 방면에서 악의적인 공격을 받을 수 있다. 수기스에 따르면, 이들은 관리가 제대로 이루어지지 않는 프로젝트의 개발팀에 침투하여 소프트웨어에 바로 악성 코드를 추가할 수 있다. 거기서 끝나지 않고 훈련 데이터, 미세 조정 또는 가중치까지 오염시킬 수 있다.\\n수기스는 “해커는 예시 악성 코드로 모델을 재학습시켜 사용자 인프라에 침입할 수 있다”라며 “또는 가짜 뉴스와 잘못된 정보로 모델을 훈련시킬 수도 있다”라고 설명했다.',\n","  '메타와 유사하게 애플은 ‘애플 샘플 코드 라이선스’하에 오픈ELM을 출시했다. 이 라이선스 역시 특허권은 제외하고 저작권 권한만 명시하고 있다. 애플이나 메타 모두 일반적으로 통용되는 오픈소스 라이선스를 사용하지는 않지만, 실제로 코드는 공개되어 있다. 여기에 애플은 실제로 코드뿐만 아니라 모델 가중치, 훈련 데이터 세트, 훈련 로그, 사전 훈련 구성도 공개했다.\\n이제 오픈소스 라이선스의 또 다른 측면을 살펴보자. 기존의 오픈소스 소프트웨어에서 핵심은 ‘코드’였다. 그리고 그 코드를 통해 소프트웨어가 어떤 기능을 하는지, 잠재적인 문제나 취약점이 있는지 확인할 수 있었다.\\n하지만 생성형 AI는 단순한 코드가 아니다. 학습 데이터, 모델 가중치, 미세 조정도 마찬가지다. 이러한 모든 요소는 모델의 작동 방식을 이해하고 잠재적인 편향을 파악하는 데 매우 중요다. 예를 들어, 평평한 지구 음모론에 대한 자료를 학습한 모델은 과학 관련 질문에 제대로 답하지 못할 수 있다. 북한 해커가 미세 조정한 모델은 멀웨어를 정확하게 식별하지 못할 수 있다. 그렇다면 오픈소스 LLM은 이러한 모든 정보를 공개할까? 모델에 따라 다르다. 심지어 버전에 따라 다를 수도 있다. 그만큼 관련된 업계 표준이 없다.\\n카네기멜론 대학교의 AI 교수이자 전 PwC의 글로벌 AI 사업 총괄이었 아난드 라오는 “AI 모델에서 코드를 공개하는 경우도 있지만, 미세 조정 관련 정보가 없다면 비슷한 성능을 얻기 위해 많은 비용을 지출할 수 있다”라고 설명했다.',\n","  'LLM 공격 중 유명한 것에 탈옥(jailbreak)이라는 수법이 있다. 탈옥은 의도적으로 사용자가 제시한 지침을 어기게 하고 멀웨어를 생성하도록 속이는 교묘한 프롬프트를 만드는 것이다. 일부 벤더는 탈옥 현상을 파악해서 알려주고 막는 서비스를 제공하고 있다. 오픈소스 모델에 보내는 메시지에 접근하며 의심스러운 활동의 징후를 모니터링하는 벤더도 있다.\\n악의적인 공격자가 비공개 환경에서 실행되는 엔터프라이즈 버전의 제품을 구매할 가능성은 낮다. 애초에 프롬프트 정보가 기업 내부에서만 입력되고 벤더에게 전송되지 않기 때문이다.',\n","  '현재 오픈소스 AI 라이선스 유형은 다양한 만큼 매우 복잡하다. 오픈소스 AI 모델을 이용하려면 상업적으로 사용해도 괜찮은지, 수정 및 배포가 가능한지, 사내 코드 베이스에 안전하게 통합할 수 있는지 등을 알아봐야 한다. 여기에 몇 가지 새로운 문제가 등장했다. 일단 이전에는 볼 수 없는 제약이 오픈소스 라이선스에 적용됐다.\\n메타의 라마(Llama) 라이선스를 예로 보자. 라마는 높은 인기를 자랑하는 오픈소스 LLM이다. 메타는 라마에 대해 ‘개방형 접근권을 제공하고 잠재적인 오용 문제를 해결하기 맞춤형 상용 라이선스 모델’을 적용한다고 밝혔다. 또한 이에 대해 ‘책임 및 보호 조치의 균형을 맞추기 위한 조치’라고 소개하고 있다.\\n이런 라이선스 하에 기업은 상업적으로 라마 모델을 사용할 수 있고 개발자는 기본 라마 모델 위에 추가 작업을 만들어 배포할 수 있다. 단 다른 LLM을 개선하기 위해 라마가 출력하는 결과물을 활용할 수는 없다. (라마 파생 모델은 제외된다.) 또한 기업 또는 그 계열사의 월간 사용자가 700명을 초과하는 경우, 메타에게 라이선스 사용 허락을 요청해야 한다. 메타는 이를 승인하거나 승인하지 않을 수 있다. 어떤 기업에서 라마 3를 사용해서 뭔가를 만들었다면, 눈에 잘 띄는 위치에 ‘Built with Llama 3(라마 3를 기반으로 구축했음)’라는 문구를 표기해야 한다.',\n","  '또 다른 공격 벡터는 모델의 시스템 프롬프트이다. 수기스에 따르면시스템 프롬프트는 일반 사용자에게 보통 공개되지 않는다. 시스템 프롬프트는 모델이 원치 않거나 비윤리적인 행동을 인식하는 안전망을 포함하고 있기에 중요하다. 수기스는 “해커가 시스템 프롬프트에 접근해서 모델을 공격하는 방법을 알아낼 수 있다”라고 설명했다.',\n","  '예술가, 작가, 기타 저작권 소유자들이 대형 AI 기업을 상대로 소송을 제기하고 있다. 하지만 오픈소스 모델이 지적재산권을 침해하고, 그 모델을 제품이나 서비스에 도입한 기업들만 큰돈을 벌고 있다면 어떻게 될까? 기업 사용자가 소송을 당할 수도 있을까?\\nEY의 구아레라는 “잠재적인 위험성은 있다. 법원에서 진행 중인 관련 소송이 어떤 결과를 맞이할지는 아직 아무도 모른다”라며 “데이터세트에 대한 보상이 있어야 하는 사회로 향하고 있을지도 모른다”라고 분석했다. 또한 구아레라는 “대형 기술 업체는 앞으로 늘어날 저작권 관련 위기를 극복하고 필요한 자금을 확보할 수 있는 더 나은 위치에 있다”라고 평가했다.',\n","  '오픈소스 기술을 소비하는 기업이 표준과 호환성을 중시하는 경우가 많다. 그래서 사용자 주도의 오픈소스 프로젝트는 보통 기존에 나온 표준을 따를 때가 많다.\\n실제로 리눅스 재단이 약 500명의 기술 전문가를 대상으로 진행한 작년 설문조사에 따르면, 71%가 개방형 표준을 선호하는 반면, 폐쇄형 표준을 선호하는 응답자는 10%에 불과했다. 보통 상용 소프트웨어 업체는 고객이 자사 기술 생태계에 갇혀 있는 것을 선호한다. 오픈소스 기술은 다를 것이라고 기대할 수 있지만, 표준을 따르지 않는 생성형 AI 기술은 꽤 있다.',\n","  '반면에 악의적인 공격자는 접근하기 쉬운 오픈소스 모델을 무료로 다운로드하여 자신의 환경에서 실행하며 해킹을 시도할 수 있다. 또한 모델이 사용하는 시스템 프롬프트와 안전 기능까지 다 볼 수 있기 때문에 탈옥을 위한 유리한 고지를 선점할 수 있다. 기업에선 오픈소스 AI 모델 전문 보안 담당자가 없는 경우가 많기 때문에 이런 공격에 취약할 수 있다. 라오는 “예를 들어 공격자는 학습 데이터를 분석하여 모델이 이미지를 잘못 식별하거나 사용자가 인식하지 못하게 문제 없어 보이는 프롬프트를 만드는 방법을 알아낼 수 있다”라고 설명했다.\\nAI 모델 출력물에 워터마크를 추가해도 공격을 막지 못할 수도 있다. 악의적인 공격자가 코드를 분석 및 리버스 엔지니어링을 통해 워터마크를 제거할 수 있기 때문이다. 또한 공격자는 모델이나 기타 지원 코드 및 도구를 분석하여 취약한 영역을 찾을 수도 있다.\\n컨설팅 업체인 노탈(Nortal)의 수석 데이터 과학자인 엘레나 수기스는 “공격자는 특정 요청을 계속 보내 인프라를 과부하시켜 모델이 작동하지 않도록 만들 수 있다”라며 “모델이 특정 시스템의 일부이고 모델 출력 결과가 시스템의 다른 부분에서 사용되는 경우 문제가 될 수 있다. 특히 모델의 출력 생성 방식을 공격할 수 있다면 전체 시스템이 중단될 수 있다. 기업에 매우 위험한 일이다”라고 말했다.',\n","  '오픈소스 그룹 일각에서는 AI 모델에 가드레일(허용 가능한 범위를 두는 일종의 가이드라인 또는 도구)을 두는 것 자체를 반대하기도 한다. 모델에 아무런 제한 없어야 더 나은 성능을 발휘할 것이라 믿는 곳도 있다. 기업은 현재 사용하는 오픈소스 모델이 가드레일에 대해 어떤 방향을 추구하는지조차 잘 모를 수도 있다.\\n수기스는 “현재 오픈소스 생성형 AI 모델의 안전성을 평가하는 독립적인 기관은 없다”라며 “유럽의 AI 법은 이러한 문서를 일부 요구할 것이지만, 대부분의 조항은 2026년에야 시행될 것”이라고 밝혔다. 또한 수기스는 “나라면 가능한 한 많은 문서를 확보하고, 모델을 테스트 및 평가하고, 회사 내부에 몇 가지 보호 장치를 마련할 것”이라고 밝혔다.',\n","  '업계 전체에 전문성이 부족하다는 점은 새로운 문제를 야기한다. 원래 오픈소스의 장점 중 하나는 수많은 사람이 코드를 살펴보고 프로그래밍 오류, 보안 취약점 및 기타 약점을 발견할 수 있다는 부분이다. 마치 외부의 ‘천개의 눈’으로 문제점을 공동으로 확인하는 셈이다. 기존의 오픈소스 소프트웨어야 수많은 전문가가 있어 천개의 눈을 가질 수 있었지만 AI 분야에서는 전문가가 부족하다. 천개의 눈을 아직 모으지 못했으니 보안 취약점에 제대로 대응하지 못할 수도 있다.',\n","  '오픈소스는 스스로 해야 하는 작업이 많을 수 있다. 기업은 코드를 다운로드할 수는 있지만, 제대로 작동시키려면 사내 전문가나 외부 컨설턴트가 필요할 수 있다. 이는 생성형 AI 분야에서 큰 문제다. 이제 막 나온 기술과 관련해서 수년간의 경험을 가진 사람은 존재할 수 없다. 라오는 그런면에서 생성형 AI를 완전 처음 시작하거나 빠르게 도입하고 싶은 기업이라면 차라리 상용 플랫폼으로 시작하는 것이 더 안전하다고 조언했다.\\n라오는 “오픈소스 버전을 다운로드하려면 전문 지식이 필요하다”라며 “개념 증명을 완료하고 모델을 실제 제품에 배포 후 비용이 늘어나고 있다면, 오픈소스의 대안을 본격적으로 살펴봐야 할 것”이라고 설명했다.',\n","  '노탈의 수기스는 “대형 벤더는 학습 데이터를 구입하고 소송을 벌이는 데 쓸 돈이 있을 뿐만 아니라, 선별된 데이터 세트에 쓸 돈도 있다”라고 설명했다. 무료로 공개된 데이터 세트에는 합법적인 콘텐츠만 있는 것이 아니다. 일부는 저작권이 있는데 허가 없이 포함된 상태일 수 있다. 거기다 부정확하고 편향된 정보, 멀웨어 및 출력 품질을 저하시킬 수 있는 기타 자료도 들어가 있다.\\n수기스는 “많은 모델 개발자가 큐레이션된 데이터를 사용하자고 이야기하고 있다”라며 “하지만 그렇게 하려면 인터넷 전체를 학습시키는 것보다 비용이 더 많이 든다”라고 밝혔다. ',\n","  '사실 많은 사람이 AI 표준에 대해 이야기할 때 윤리, 개인정보 보호, 설명 가능성 등을 이야기한다. 실제로 작년 12월에 발표된 ISO/IEC 42001 표준과 같은 작업이 해당 영역을 다루고 있다. 그리고 지난 4월 미국 국립표준기술연구소(NIST)는 AI 관련 공통 언어를 제시하는 등 AI 표준 계획 초안을 발표했다. 여기에선 주로 위험과 거버넌스 문제에 초점을 맞추고 있다. 그럼에도 기술 표준에 관해서는 아직 정해진 것이 많지 않다.\\n클라우드 네이티브 컴퓨팅 재단의 CIO인 테일러 돌잘은 “표준에 대한 논의는 매우 초기 단계에 머물러 있다”라며 ”단 데이터 분류, 학습 데이터, API, 프롬프트에 대한 표준 형식에 대해 의미 있는 논의가 이뤄지고 있다”라고 말했다. 그래도 아직 ‘논의’하는 수준일 뿐이다.'],\n"," 'uris': None,\n"," 'data': None}"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["database.get()"]},{"cell_type":"markdown","metadata":{"id":"6a6yqWre7dR8"},"source":["### (2) 질문으로 유사도 높은 문서 조회하기"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"1mEKTMMS7dR8"},"outputs":[{"name":"stdout","output_type":"stream","text":["[(Document(page_content='생성형 AI 프로젝트는 단순한 코드 그 이상이기 때문에 잠재적으로 보안 위협에 노출될 수 있는 영역이 더 많다. LLM은 여러 방면에서 악의적인 공격을 받을 수 있다. 수기스에 따르면, 이들은 관리가 제대로 이루어지지 않는 프로젝트의 개발팀에 침투하여 소프트웨어에 바로 악성 코드를 추가할 수 있다. 거기서 끝나지 않고 훈련 데이터, 미세 조정 또는 가중치까지 오염시킬 수 있다.\\n수기스는 “해커는 예시 악성 코드로 모델을 재학습시켜 사용자 인프라에 침입할 수 있다”라며 “또는 가짜 뉴스와 잘못된 정보로 모델을 훈련시킬 수도 있다”라고 설명했다.'), 0.2519096048124197), (Document(page_content='사실 많은 사람이 AI 표준에 대해 이야기할 때 윤리, 개인정보 보호, 설명 가능성 등을 이야기한다. 실제로 작년 12월에 발표된 ISO/IEC 42001 표준과 같은 작업이 해당 영역을 다루고 있다. 그리고 지난 4월 미국 국립표준기술연구소(NIST)는 AI 관련 공통 언어를 제시하는 등 AI 표준 계획 초안을 발표했다. 여기에선 주로 위험과 거버넌스 문제에 초점을 맞추고 있다. 그럼에도 기술 표준에 관해서는 아직 정해진 것이 많지 않다.\\n클라우드 네이티브 컴퓨팅 재단의 CIO인 테일러 돌잘은 “표준에 대한 논의는 매우 초기 단계에 머물러 있다”라며 ”단 데이터 분류, 학습 데이터, API, 프롬프트에 대한 표준 형식에 대해 의미 있는 논의가 이뤄지고 있다”라고 말했다. 그래도 아직 ‘논의’하는 수준일 뿐이다.'), 0.2645925343300896), (Document(page_content='오픈소스 그룹 일각에서는 AI 모델에 가드레일(허용 가능한 범위를 두는 일종의 가이드라인 또는 도구)을 두는 것 자체를 반대하기도 한다. 모델에 아무런 제한 없어야 더 나은 성능을 발휘할 것이라 믿는 곳도 있다. 기업은 현재 사용하는 오픈소스 모델이 가드레일에 대해 어떤 방향을 추구하는지조차 잘 모를 수도 있다.\\n수기스는 “현재 오픈소스 생성형 AI 모델의 안전성을 평가하는 독립적인 기관은 없다”라며 “유럽의 AI 법은 이러한 문서를 일부 요구할 것이지만, 대부분의 조항은 2026년에야 시행될 것”이라고 밝혔다. 또한 수기스는 “나라면 가능한 한 많은 문서를 확보하고, 모델을 테스트 및 평가하고, 회사 내부에 몇 가지 보호 장치를 마련할 것”이라고 밝혔다.'), 0.26686577146136886), (Document(page_content='반면에 악의적인 공격자는 접근하기 쉬운 오픈소스 모델을 무료로 다운로드하여 자신의 환경에서 실행하며 해킹을 시도할 수 있다. 또한 모델이 사용하는 시스템 프롬프트와 안전 기능까지 다 볼 수 있기 때문에 탈옥을 위한 유리한 고지를 선점할 수 있다. 기업에선 오픈소스 AI 모델 전문 보안 담당자가 없는 경우가 많기 때문에 이런 공격에 취약할 수 있다. 라오는 “예를 들어 공격자는 학습 데이터를 분석하여 모델이 이미지를 잘못 식별하거나 사용자가 인식하지 못하게 문제 없어 보이는 프롬프트를 만드는 방법을 알아낼 수 있다”라고 설명했다.\\nAI 모델 출력물에 워터마크를 추가해도 공격을 막지 못할 수도 있다. 악의적인 공격자가 코드를 분석 및 리버스 엔지니어링을 통해 워터마크를 제거할 수 있기 때문이다. 또한 공격자는 모델이나 기타 지원 코드 및 도구를 분석하여 취약한 영역을 찾을 수도 있다.\\n컨설팅 업체인 노탈(Nortal)의 수석 데이터 과학자인 엘레나 수기스는 “공격자는 특정 요청을 계속 보내 인프라를 과부하시켜 모델이 작동하지 않도록 만들 수 있다”라며 “모델이 특정 시스템의 일부이고 모델 출력 결과가 시스템의 다른 부분에서 사용되는 경우 문제가 될 수 있다. 특히 모델의 출력 생성 방식을 공격할 수 있다면 전체 시스템이 중단될 수 있다. 기업에 매우 위험한 일이다”라고 말했다.'), 0.2683695671724876), (Document(page_content='예술가, 작가, 기타 저작권 소유자들이 대형 AI 기업을 상대로 소송을 제기하고 있다. 하지만 오픈소스 모델이 지적재산권을 침해하고, 그 모델을 제품이나 서비스에 도입한 기업들만 큰돈을 벌고 있다면 어떻게 될까? 기업 사용자가 소송을 당할 수도 있을까?\\nEY의 구아레라는 “잠재적인 위험성은 있다. 법원에서 진행 중인 관련 소송이 어떤 결과를 맞이할지는 아직 아무도 모른다”라며 “데이터세트에 대한 보상이 있어야 하는 사회로 향하고 있을지도 모른다”라고 분석했다. 또한 구아레라는 “대형 기술 업체는 앞으로 늘어날 저작권 관련 위기를 극복하고 필요한 자금을 확보할 수 있는 더 나은 위치에 있다”라고 평가했다.'), 0.27528721259416916)]\n","--------------------------------------------------\n","유사도 점수 : 0.25191, 문서 내용: 생성형 AI 프로젝트는 단순한 코드 그 이상이기 때문에 잠재적으로 보안 위협에 노출될 수 있는 영역이 더 많다. LLM은 여러 방면에서 악의적인 공격을 받을 수 있다. 수기스에 따르면, 이들은 관리가 제대로 이루어지지 않는 프로젝트의 개발팀에 침투하여 소프트웨어에 바로 악성 코드를 추가할 수 있다. 거기서 끝나지 않고 훈련 데이터, 미세 조정 또는 가중치까지 오염시킬 수 있다.\n","수기스는 “해커는 예시 악성 코드로 모델을 재학습시켜 사용자 인프라에 침입할 수 있다”라며 “또는 가짜 뉴스와 잘못된 정보로 모델을 훈련시킬 수도 있다”라고 설명했다.\n","유사도 점수 : 0.26459, 문서 내용: 사실 많은 사람이 AI 표준에 대해 이야기할 때 윤리, 개인정보 보호, 설명 가능성 등을 이야기한다. 실제로 작년 12월에 발표된 ISO/IEC 42001 표준과 같은 작업이 해당 영역을 다루고 있다. 그리고 지난 4월 미국 국립표준기술연구소(NIST)는 AI 관련 공통 언어를 제시하는 등 AI 표준 계획 초안을 발표했다. 여기에선 주로 위험과 거버넌스 문제에 초점을 맞추고 있다. 그럼에도 기술 표준에 관해서는 아직 정해진 것이 많지 않다.\n","클라우드 네이티브 컴퓨팅 재단의 CIO인 테일러 돌잘은 “표준에 대한 논의는 매우 초기 단계에 머물러 있다”라며 ”단 데이터 분류, 학습 데이터, API, 프롬프트에 대한 표준 형식에 대해 의미 있는 논의가 이뤄지고 있다”라고 말했다. 그래도 아직 ‘논의’하는 수준일 뿐이다.\n","유사도 점수 : 0.26687, 문서 내용: 오픈소스 그룹 일각에서는 AI 모델에 가드레일(허용 가능한 범위를 두는 일종의 가이드라인 또는 도구)을 두는 것 자체를 반대하기도 한다. 모델에 아무런 제한 없어야 더 나은 성능을 발휘할 것이라 믿는 곳도 있다. 기업은 현재 사용하는 오픈소스 모델이 가드레일에 대해 어떤 방향을 추구하는지조차 잘 모를 수도 있다.\n","수기스는 “현재 오픈소스 생성형 AI 모델의 안전성을 평가하는 독립적인 기관은 없다”라며 “유럽의 AI 법은 이러한 문서를 일부 요구할 것이지만, 대부분의 조항은 2026년에야 시행될 것”이라고 밝혔다. 또한 수기스는 “나라면 가능한 한 많은 문서를 확보하고, 모델을 테스트 및 평가하고, 회사 내부에 몇 가지 보호 장치를 마련할 것”이라고 밝혔다.\n","유사도 점수 : 0.26837, 문서 내용: 반면에 악의적인 공격자는 접근하기 쉬운 오픈소스 모델을 무료로 다운로드하여 자신의 환경에서 실행하며 해킹을 시도할 수 있다. 또한 모델이 사용하는 시스템 프롬프트와 안전 기능까지 다 볼 수 있기 때문에 탈옥을 위한 유리한 고지를 선점할 수 있다. 기업에선 오픈소스 AI 모델 전문 보안 담당자가 없는 경우가 많기 때문에 이런 공격에 취약할 수 있다. 라오는 “예를 들어 공격자는 학습 데이터를 분석하여 모델이 이미지를 잘못 식별하거나 사용자가 인식하지 못하게 문제 없어 보이는 프롬프트를 만드는 방법을 알아낼 수 있다”라고 설명했다.\n","AI 모델 출력물에 워터마크를 추가해도 공격을 막지 못할 수도 있다. 악의적인 공격자가 코드를 분석 및 리버스 엔지니어링을 통해 워터마크를 제거할 수 있기 때문이다. 또한 공격자는 모델이나 기타 지원 코드 및 도구를 분석하여 취약한 영역을 찾을 수도 있다.\n","컨설팅 업체인 노탈(Nortal)의 수석 데이터 과학자인 엘레나 수기스는 “공격자는 특정 요청을 계속 보내 인프라를 과부하시켜 모델이 작동하지 않도록 만들 수 있다”라며 “모델이 특정 시스템의 일부이고 모델 출력 결과가 시스템의 다른 부분에서 사용되는 경우 문제가 될 수 있다. 특히 모델의 출력 생성 방식을 공격할 수 있다면 전체 시스템이 중단될 수 있다. 기업에 매우 위험한 일이다”라고 말했다.\n","유사도 점수 : 0.27529, 문서 내용: 예술가, 작가, 기타 저작권 소유자들이 대형 AI 기업을 상대로 소송을 제기하고 있다. 하지만 오픈소스 모델이 지적재산권을 침해하고, 그 모델을 제품이나 서비스에 도입한 기업들만 큰돈을 벌고 있다면 어떻게 될까? 기업 사용자가 소송을 당할 수도 있을까?\n","EY의 구아레라는 “잠재적인 위험성은 있다. 법원에서 진행 중인 관련 소송이 어떤 결과를 맞이할지는 아직 아무도 모른다”라며 “데이터세트에 대한 보상이 있어야 하는 사회로 향하고 있을지도 모른다”라고 분석했다. 또한 구아레라는 “대형 기술 업체는 앞으로 늘어날 저작권 관련 위기를 극복하고 필요한 자금을 확보할 수 있는 더 나은 위치에 있다”라고 평가했다.\n"]}],"source":["# 문서 조회 : 유사도 점수도 함께 조회\n","query = \"생성형 AI 도입시 예상되는 보안 위협은 어떤 것들이 있어?\"   # 질문할 문장\n","k = 5                      # 유사도 상위 k 개 문서 가져오기.\n","\n","result = database.similarity_search_with_score(query, k = k) #← 데이터베이스에서 유사도가 높은 문서를 가져옴\n","print(result)\n","print('-'*50)\n","for doc in result:\n","    print(f\"유사도 점수 : {round(doc[1], 5)}, 문서 내용: {doc[0].page_content}\") # 문서 내용 표시"]},{"cell_type":"markdown","metadata":{"id":"y8I9UoAA7dR8"},"source":["### (3) 질문에 대한 답변 받기\n","* 절차\n","    * 질문을 받아\n","    * 유사도 높은 문서를 DB에서 검색(RAG)\n","    * 질문과 유사도높은 문서로 프롬프트 구성\n","    * GPT에 질문하고 답변 받기\n","\n","* RetrievalQA\n","    * 랭체인에서 제공하는 체인 함수\n","    * RAG + QA"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"mOzhAMiS7dR9"},"outputs":[{"name":"stdout","output_type":"stream","text":["생성형 AI 도입시 예상되는 보안 위협은 다양합니다. 몇 가지 예시로는 악의적인 공격자가 프로젝트의 개발팀에 침투하여 소프트웨어에 악성 코드를 추가하는 것, 훈련 데이터나 모델을 오염시키는 것, 모델을 재학습시켜 사용자 인프라에 침입하는 것, 가짜 뉴스나 잘못된 정보로 모델을 훈련시키는 것 등이 있습니다. 또한, 오픈소스 AI 모델을 다운로드하거나 분석하여 해킹을 시도하는 공격자들도 있습니다. 이러한 위협들을 감안하여 보안에 신경을 써야 합니다.\n"]}],"source":["chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n","retriever = database.as_retriever()\n","qa = RetrievalQA.from_llm(llm=chat,  retriever=retriever,  return_source_documents=True, )\n","\n","result = qa(query)\n","\n","print(result[\"result\"])"]},{"cell_type":"markdown","metadata":{"id":"8GtPOGcV7dR9"},"source":["* 유사도 높은 문서 4개를 조회하는 것이 기본값임."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Sdih3Ige7dR9"},"outputs":[{"data":{"text/plain":["{'query': '생성형 AI 도입시 예상되는 보안 위협은 어떤 것들이 있어?',\n"," 'result': '생성형 AI 도입시 예상되는 보안 위협은 다양합니다. 몇 가지 예시로는 악의적인 공격자가 프로젝트의 개발팀에 침투하여 소프트웨어에 악성 코드를 추가하는 것, 훈련 데이터나 모델을 오염시키는 것, 모델을 재학습시켜 사용자 인프라에 침입하는 것, 가짜 뉴스나 잘못된 정보로 모델을 훈련시키는 것 등이 있습니다. 또한, 오픈소스 AI 모델을 다운로드하거나 분석하여 해킹을 시도하는 공격자들도 있습니다. 이러한 위협들을 감안하여 보안에 신경을 써야 합니다.',\n"," 'source_documents': [Document(page_content='생성형 AI 프로젝트는 단순한 코드 그 이상이기 때문에 잠재적으로 보안 위협에 노출될 수 있는 영역이 더 많다. LLM은 여러 방면에서 악의적인 공격을 받을 수 있다. 수기스에 따르면, 이들은 관리가 제대로 이루어지지 않는 프로젝트의 개발팀에 침투하여 소프트웨어에 바로 악성 코드를 추가할 수 있다. 거기서 끝나지 않고 훈련 데이터, 미세 조정 또는 가중치까지 오염시킬 수 있다.\\n수기스는 “해커는 예시 악성 코드로 모델을 재학습시켜 사용자 인프라에 침입할 수 있다”라며 “또는 가짜 뉴스와 잘못된 정보로 모델을 훈련시킬 수도 있다”라고 설명했다.'),\n","  Document(page_content='사실 많은 사람이 AI 표준에 대해 이야기할 때 윤리, 개인정보 보호, 설명 가능성 등을 이야기한다. 실제로 작년 12월에 발표된 ISO/IEC 42001 표준과 같은 작업이 해당 영역을 다루고 있다. 그리고 지난 4월 미국 국립표준기술연구소(NIST)는 AI 관련 공통 언어를 제시하는 등 AI 표준 계획 초안을 발표했다. 여기에선 주로 위험과 거버넌스 문제에 초점을 맞추고 있다. 그럼에도 기술 표준에 관해서는 아직 정해진 것이 많지 않다.\\n클라우드 네이티브 컴퓨팅 재단의 CIO인 테일러 돌잘은 “표준에 대한 논의는 매우 초기 단계에 머물러 있다”라며 ”단 데이터 분류, 학습 데이터, API, 프롬프트에 대한 표준 형식에 대해 의미 있는 논의가 이뤄지고 있다”라고 말했다. 그래도 아직 ‘논의’하는 수준일 뿐이다.'),\n","  Document(page_content='오픈소스 그룹 일각에서는 AI 모델에 가드레일(허용 가능한 범위를 두는 일종의 가이드라인 또는 도구)을 두는 것 자체를 반대하기도 한다. 모델에 아무런 제한 없어야 더 나은 성능을 발휘할 것이라 믿는 곳도 있다. 기업은 현재 사용하는 오픈소스 모델이 가드레일에 대해 어떤 방향을 추구하는지조차 잘 모를 수도 있다.\\n수기스는 “현재 오픈소스 생성형 AI 모델의 안전성을 평가하는 독립적인 기관은 없다”라며 “유럽의 AI 법은 이러한 문서를 일부 요구할 것이지만, 대부분의 조항은 2026년에야 시행될 것”이라고 밝혔다. 또한 수기스는 “나라면 가능한 한 많은 문서를 확보하고, 모델을 테스트 및 평가하고, 회사 내부에 몇 가지 보호 장치를 마련할 것”이라고 밝혔다.'),\n","  Document(page_content='반면에 악의적인 공격자는 접근하기 쉬운 오픈소스 모델을 무료로 다운로드하여 자신의 환경에서 실행하며 해킹을 시도할 수 있다. 또한 모델이 사용하는 시스템 프롬프트와 안전 기능까지 다 볼 수 있기 때문에 탈옥을 위한 유리한 고지를 선점할 수 있다. 기업에선 오픈소스 AI 모델 전문 보안 담당자가 없는 경우가 많기 때문에 이런 공격에 취약할 수 있다. 라오는 “예를 들어 공격자는 학습 데이터를 분석하여 모델이 이미지를 잘못 식별하거나 사용자가 인식하지 못하게 문제 없어 보이는 프롬프트를 만드는 방법을 알아낼 수 있다”라고 설명했다.\\nAI 모델 출력물에 워터마크를 추가해도 공격을 막지 못할 수도 있다. 악의적인 공격자가 코드를 분석 및 리버스 엔지니어링을 통해 워터마크를 제거할 수 있기 때문이다. 또한 공격자는 모델이나 기타 지원 코드 및 도구를 분석하여 취약한 영역을 찾을 수도 있다.\\n컨설팅 업체인 노탈(Nortal)의 수석 데이터 과학자인 엘레나 수기스는 “공격자는 특정 요청을 계속 보내 인프라를 과부하시켜 모델이 작동하지 않도록 만들 수 있다”라며 “모델이 특정 시스템의 일부이고 모델 출력 결과가 시스템의 다른 부분에서 사용되는 경우 문제가 될 수 있다. 특히 모델의 출력 생성 방식을 공격할 수 있다면 전체 시스템이 중단될 수 있다. 기업에 매우 위험한 일이다”라고 말했다.')]}"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["result"]},{"cell_type":"markdown","metadata":{"id":"pwow3NOR7dR9"},"source":["* 유사도 높은 문서 k개로부터 프롬프트 구성하여 질의하기"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"TdguFGPx7dR9"},"outputs":[{"data":{"text/plain":["{'query': '생성형 AI 도입시 예상되는 보안 위협은 어떤 것들이 있어?',\n"," 'result': '생성형 AI 도입시 예상되는 보안 위협은 다양한 형태로 나타날 수 있습니다. 몇 가지 예시로는 악의적인 공격자가 프로젝트의 개발팀에 침투하여 소프트웨어에 악성 코드를 추가하거나, 훈련 데이터나 미세 조정을 통해 모델을 오염시키는 경우가 있을 수 있습니다. 또한, 오픈소스 모델을 다운로드하여 해킹을 시도하는 등의 위협도 존재할 수 있습니다. 이러한 위협을 방지하고 대비하기 위해서는 안전한 데이터 처리 및 모델 평가를 신중히 진행하는 것이 중요합니다.',\n"," 'source_documents': [Document(page_content='생성형 AI 프로젝트는 단순한 코드 그 이상이기 때문에 잠재적으로 보안 위협에 노출될 수 있는 영역이 더 많다. LLM은 여러 방면에서 악의적인 공격을 받을 수 있다. 수기스에 따르면, 이들은 관리가 제대로 이루어지지 않는 프로젝트의 개발팀에 침투하여 소프트웨어에 바로 악성 코드를 추가할 수 있다. 거기서 끝나지 않고 훈련 데이터, 미세 조정 또는 가중치까지 오염시킬 수 있다.\\n수기스는 “해커는 예시 악성 코드로 모델을 재학습시켜 사용자 인프라에 침입할 수 있다”라며 “또는 가짜 뉴스와 잘못된 정보로 모델을 훈련시킬 수도 있다”라고 설명했다.'),\n","  Document(page_content='사실 많은 사람이 AI 표준에 대해 이야기할 때 윤리, 개인정보 보호, 설명 가능성 등을 이야기한다. 실제로 작년 12월에 발표된 ISO/IEC 42001 표준과 같은 작업이 해당 영역을 다루고 있다. 그리고 지난 4월 미국 국립표준기술연구소(NIST)는 AI 관련 공통 언어를 제시하는 등 AI 표준 계획 초안을 발표했다. 여기에선 주로 위험과 거버넌스 문제에 초점을 맞추고 있다. 그럼에도 기술 표준에 관해서는 아직 정해진 것이 많지 않다.\\n클라우드 네이티브 컴퓨팅 재단의 CIO인 테일러 돌잘은 “표준에 대한 논의는 매우 초기 단계에 머물러 있다”라며 ”단 데이터 분류, 학습 데이터, API, 프롬프트에 대한 표준 형식에 대해 의미 있는 논의가 이뤄지고 있다”라고 말했다. 그래도 아직 ‘논의’하는 수준일 뿐이다.'),\n","  Document(page_content='오픈소스 그룹 일각에서는 AI 모델에 가드레일(허용 가능한 범위를 두는 일종의 가이드라인 또는 도구)을 두는 것 자체를 반대하기도 한다. 모델에 아무런 제한 없어야 더 나은 성능을 발휘할 것이라 믿는 곳도 있다. 기업은 현재 사용하는 오픈소스 모델이 가드레일에 대해 어떤 방향을 추구하는지조차 잘 모를 수도 있다.\\n수기스는 “현재 오픈소스 생성형 AI 모델의 안전성을 평가하는 독립적인 기관은 없다”라며 “유럽의 AI 법은 이러한 문서를 일부 요구할 것이지만, 대부분의 조항은 2026년에야 시행될 것”이라고 밝혔다. 또한 수기스는 “나라면 가능한 한 많은 문서를 확보하고, 모델을 테스트 및 평가하고, 회사 내부에 몇 가지 보호 장치를 마련할 것”이라고 밝혔다.'),\n","  Document(page_content='반면에 악의적인 공격자는 접근하기 쉬운 오픈소스 모델을 무료로 다운로드하여 자신의 환경에서 실행하며 해킹을 시도할 수 있다. 또한 모델이 사용하는 시스템 프롬프트와 안전 기능까지 다 볼 수 있기 때문에 탈옥을 위한 유리한 고지를 선점할 수 있다. 기업에선 오픈소스 AI 모델 전문 보안 담당자가 없는 경우가 많기 때문에 이런 공격에 취약할 수 있다. 라오는 “예를 들어 공격자는 학습 데이터를 분석하여 모델이 이미지를 잘못 식별하거나 사용자가 인식하지 못하게 문제 없어 보이는 프롬프트를 만드는 방법을 알아낼 수 있다”라고 설명했다.\\nAI 모델 출력물에 워터마크를 추가해도 공격을 막지 못할 수도 있다. 악의적인 공격자가 코드를 분석 및 리버스 엔지니어링을 통해 워터마크를 제거할 수 있기 때문이다. 또한 공격자는 모델이나 기타 지원 코드 및 도구를 분석하여 취약한 영역을 찾을 수도 있다.\\n컨설팅 업체인 노탈(Nortal)의 수석 데이터 과학자인 엘레나 수기스는 “공격자는 특정 요청을 계속 보내 인프라를 과부하시켜 모델이 작동하지 않도록 만들 수 있다”라며 “모델이 특정 시스템의 일부이고 모델 출력 결과가 시스템의 다른 부분에서 사용되는 경우 문제가 될 수 있다. 특히 모델의 출력 생성 방식을 공격할 수 있다면 전체 시스템이 중단될 수 있다. 기업에 매우 위험한 일이다”라고 말했다.'),\n","  Document(page_content='예술가, 작가, 기타 저작권 소유자들이 대형 AI 기업을 상대로 소송을 제기하고 있다. 하지만 오픈소스 모델이 지적재산권을 침해하고, 그 모델을 제품이나 서비스에 도입한 기업들만 큰돈을 벌고 있다면 어떻게 될까? 기업 사용자가 소송을 당할 수도 있을까?\\nEY의 구아레라는 “잠재적인 위험성은 있다. 법원에서 진행 중인 관련 소송이 어떤 결과를 맞이할지는 아직 아무도 모른다”라며 “데이터세트에 대한 보상이 있어야 하는 사회로 향하고 있을지도 모른다”라고 분석했다. 또한 구아레라는 “대형 기술 업체는 앞으로 늘어날 저작권 관련 위기를 극복하고 필요한 자금을 확보할 수 있는 더 나은 위치에 있다”라고 평가했다.')]}"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["k = 5\n","retriever = database.as_retriever(search_kwargs={\"k\": k})\n","\n","qa = RetrievalQA.from_llm(llm=chat,  retriever=retriever,  return_source_documents=True, )\n","\n","result = qa(query)\n","result"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
